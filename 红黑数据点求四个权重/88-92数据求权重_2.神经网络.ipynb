{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('88-92.csv',usecols=[ 'GDP/面积', '路距','熵','湖距','label'])\n",
    "print(data.shape) # (235, 5)\n",
    "print(type(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP/面积</th>\n",
       "      <th>路距</th>\n",
       "      <th>熵</th>\n",
       "      <th>湖距</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990951</td>\n",
       "      <td>0.618756</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>0.665135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973786</td>\n",
       "      <td>0.811400</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>0.737388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.963077</td>\n",
       "      <td>0.737421</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>0.773321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.980047</td>\n",
       "      <td>0.775631</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>0.768556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989406</td>\n",
       "      <td>0.719091</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>0.778399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GDP/面积        路距         熵        湖距  label\n",
       "0  0.990951  0.618756  0.657462  0.665135      0\n",
       "1  0.973786  0.811400  0.657462  0.737388      0\n",
       "2  0.963077  0.737421  0.657462  0.773321      0\n",
       "3  0.980047  0.775631  0.657462  0.768556      0\n",
       "4  0.989406  0.719091  0.657462  0.778399      0"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 4)\n",
      "(235,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 划分数据获取X，y\n",
    "X = data[['GDP/面积', '路距','熵','湖距']]\n",
    "Y = data['label']\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(type(Y))\n",
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(235, 4)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 修改X,y数据类型：<class 'pandas.core.frame.DataFrame'> ---> <class 'numpy.ndarray'>\n",
    "import numpy as np\n",
    "X = np.array(X)\n",
    "Y = Y.values.tolist()\n",
    "print(type(Y))\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "# X= tf.convert_to_tensor(X,dtype=tf.float32)\n",
    "# y = tf.convert_to_tensor(y,dtype=tf.float32)\n",
    "# X = X.astype(float)\n",
    "# y = y.astype(float)\n",
    "print(type(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_x: <class 'numpy.ndarray'>\n",
      "type_y: <class 'list'>\n",
      "(?, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"type_x:\",type(X))\n",
    "print(\"type_y:\",type(Y))\n",
    "print(x.shape) #(?, 4)\n",
    "# print(y.shape)#(?, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络实现二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([4,3],stddev=1,seed=1))  # 因为含有4个属性值\n",
    "w2 = tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "\n",
    "# w1 = tf.convert_to_tensor(w1)\n",
    "# w1 = tf.convert_to_tensor(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义placeholder作为存放输入数据的地方，这里维度不一定要定义\n",
    "x = tf.placeholder(tf.float32,shape=(None,4),name = 'x-input')  # 2个属性特征值\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1),name = 'y-input')#用做标签\n",
    " \n",
    "#定义神经网络前向传播的过程，就是矩阵相乘  两层神经网络\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    " \n",
    "#定义损失函数和反向传播算法\n",
    "#用sigmoid将函数收敛到0~1之间\n",
    "y = tf.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义交叉熵损失函数，用于权衡输出值和标签值的差异\n",
    "cross_entropy = -tf.reduce_mean(\n",
    "    y_*tf.log(tf.clip_by_value(y,1e-10,1.0))\n",
    "    +(1-y)*tf.log(tf.clip_by_value(1-y,1e-10,1.0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#优化算法lr=0.001\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "len_Y 235\n",
      "-----------------------------\n",
      "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]\n",
      "len_Y 235\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 张量转化为ndarray  t为张量\n",
    "array = session.run(t)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "testy = X[0:5]\n",
    "print(type(testy))\n",
    "sess = tf.Session()\n",
    "ny = testy.eval(session=sess)\n",
    "print(type(ny))\n",
    "\"\"\"\n",
    "print(Y)\n",
    "print(\"len_Y\",len(Y))\n",
    "list = Y\n",
    "Y = []\n",
    "for i in list:\n",
    "    Y.append([i])\n",
    "print(\"-----------------------------\")\n",
    "print(Y)\n",
    "print(\"len_Y\",len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]\n",
      " [ 0.59282297 -2.1229296  -0.72289723]\n",
      " [-0.05627038  0.6435448  -0.26432407]]\n",
      "[[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "cross entropy on all data is 0.32340625\n",
      "cross entropy on all data is 0.0064331894\n",
      "cross entropy on all data is 0.0015025854\n",
      "cross entropy on all data is 0.0005992206\n",
      "cross entropy on all data is 0.00029015588\n",
      "[[-1.2989208e+00  1.9476891e+00 -1.1711992e+00]\n",
      " [-2.9702058e+00  5.9634757e-01 -7.3553973e-01]\n",
      " [-1.2355413e-03 -1.5619457e+00 -2.1035061e+00]\n",
      " [-6.3040429e-01  1.1855305e+00 -1.6215870e+00]]\n",
      "[[-1.3626207]\n",
      " [ 2.0756211]\n",
      " [-1.1959031]]\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 235\n",
    "batch_size = 5\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "#创建一个会话来运行TensorFlow程序\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()#全体初始化\n",
    "    sess.run(init_op)#先跑一下初始化是必须的\n",
    " \n",
    "    print(sess.run(w1))#输出看看当前的参数\n",
    "    print(sess.run(w2))\n",
    "\n",
    "#设定训练的轮数\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size)%dataset_size#每次选取batch_size个样本进行训练\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "#         print(\"nx before:\",type(X[start:end]))\n",
    "#         nx = X[start:end].eval(session=sess)\n",
    "#         print(\"nx after\",type(nx))  # 转换成功\n",
    "#         print(\"ny before\",type(ny))\n",
    "#         ny = y[start:end].eval(session=sess)\n",
    "#         nx = y[start:end]\n",
    "#         print(type(nx))\n",
    "#         ny = y[start:end].eval(session=sess)\n",
    "        \n",
    "#     通过选取的样本训练神经网络并更新参数\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        if i%1000 == 0:\n",
    "            total_cross_entropy = sess.run(cross_entropy,feed_dict={x:X,y_:Y})\n",
    "            print(\"cross entropy on all data is\",total_cross_entropy)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://blog.csdn.net/hejunqing14/article/details/52688825\n",
    "* https://stackoverflow.com/questions/38306330/typeerror-fetch-argument-has-invalid-type-float32-must-be-a-string-or-tensor\n",
    "* https://blog.csdn.net/qq_33431368/article/details/84454635\n",
    "* https://www.cnblogs.com/smartwhite/p/8946606.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
